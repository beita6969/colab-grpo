# AFlow-GRPO: å¼€æ”¾å¼å·¥ä½œæµç»„åˆè®­ç»ƒç³»ç»Ÿ

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **æ ¸å¿ƒåˆ›æ–°**ï¼šè®©æ¨¡å‹è‡ªä¸»å­¦ä¹ å¦‚ä½•ç»„åˆ Operators æ¥è§£å†³é—®é¢˜ï¼Œè€Œä¸æ˜¯ä»é¢„å®šä¹‰é€‰é¡¹ä¸­é€‰æ‹©

## ğŸ¯ é¡¹ç›®ç†å¿µ

```
ä¼ ç»Ÿæ–¹æ³•: "è¯·é€‰æ‹©æœ€ä½³å·¥ä½œæµ: A) Custom B) Programmer C) Custom->Review"
æœ¬é¡¹ç›®æ–¹æ³•: "è¿™æ˜¯å¯ç”¨çš„Operatorsï¼Œè¯·è®¾è®¡æœ€ä¼˜å·¥ä½œæµ DSL"
```

æ¨¡å‹å­¦ä¹ ç”Ÿæˆ DSL (Domain Specific Language) æ¥ç»„åˆ Operatorsï¼Œå®ç°çœŸæ­£çš„**å¼€æ”¾å¼å·¥ä½œæµç»„åˆ**ã€‚

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AFlow-GRPO è®­ç»ƒç³»ç»Ÿ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   vLLM      â”‚â”€â”€â”€>â”‚   DSL       â”‚â”€â”€â”€>â”‚   Workflow      â”‚  â”‚
â”‚  â”‚  Generator  â”‚    â”‚   Parser    â”‚    â”‚   Executor      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                      â”‚            â”‚
â”‚         v                                      v            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   GRPO      â”‚<â”€â”€â”€â”‚   Reward    â”‚<â”€â”€â”€â”‚   Evaluator     â”‚  â”‚
â”‚  â”‚   Trainer   â”‚    â”‚   Computer  â”‚    â”‚   (gpt-4o-mini) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®­ç»ƒæµç¨‹

1. **è¾“å…¥é—®é¢˜** â†’ æ¨¡å‹æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆ DSL å·¥ä½œæµ
2. **DSL è§£æ** â†’ è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„ Python ä»£ç 
3. **å·¥ä½œæµæ‰§è¡Œ** â†’ æŒ‰ç…§ DSL é€»è¾‘æ‰§è¡Œå„ä¸ª Operator (é€šè¿‡ OpenAI API)
4. **å¥–åŠ±è®¡ç®—** â†’ è¯„ä¼°ç­”æ¡ˆæ­£ç¡®æ€§ã€æ•ˆç‡ç­‰
5. **GRPO æ›´æ–°** â†’ ä½¿ç”¨ WA-GRPO æ›´æ–°æ¨¡å‹å‚æ•°

---

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ train.py                    # ä¸»è®­ç»ƒå…¥å£
â”œâ”€â”€ train_grouped.py            # åˆ†ç»„è®­ç»ƒå…¥å£
â”œâ”€â”€ run_train.sh                # ä¸€é”®å¯åŠ¨è„šæœ¬
â”œâ”€â”€ setup_env.sh                # ç¯å¢ƒé…ç½®è„šæœ¬
â”œâ”€â”€ requirements.txt            # Pythonä¾èµ–
â”‚
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶ (10ä¸ª)
â”‚   â”œâ”€â”€ training.yaml           # ä¸»è®­ç»ƒé…ç½® (P30)
â”‚   â”œâ”€â”€ aflow_llm.yaml          # LLM API é…ç½®
â”‚   â”œâ”€â”€ datasets.yaml           # æ•°æ®é›†é…ç½®
â”‚   â”œâ”€â”€ judge_prompts.yaml      # è¯„ä¼°æç¤ºè¯
â”‚   â””â”€â”€ operator.json           # Operator å®šä¹‰
â”‚
â”œâ”€â”€ src/                        # æ ¸å¿ƒä»£ç  (23ä¸ªæ¨¡å—)
â”‚   â”œâ”€â”€ grpo_trainer.py         # GRPO è®­ç»ƒå™¨ (1425è¡Œ)
â”‚   â”œâ”€â”€ vllm_workflow_generator.py  # DSLç”Ÿæˆå™¨ (1593è¡Œ)
â”‚   â”œâ”€â”€ aflow_executor.py       # å·¥ä½œæµæ‰§è¡Œå™¨ (1197è¡Œ)
â”‚   â”œâ”€â”€ reward_computer.py      # å¥–åŠ±è®¡ç®— (2207è¡Œ)
â”‚   â”œâ”€â”€ wa_grpo.py              # WA-GRPO ä¼˜åŠ¿ä¼°è®¡
â”‚   â””â”€â”€ unified_evaluator.py    # è¯„ä¼°å™¨
â”‚
â”œâ”€â”€ scripts/                    # è¾…åŠ©è„šæœ¬ (26ä¸ª)
â”‚   â”œâ”€â”€ train_improved.py       # æ”¹è¿›è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ inference.py            # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ monitor_training.py     # è®­ç»ƒç›‘æ§
â”‚   â””â”€â”€ download_datasets.py    # æ•°æ®ä¸‹è½½
â”‚
â”œâ”€â”€ docs/                       # æŠ€æœ¯æ–‡æ¡£ (20ä¸ª)
â”‚   â”œâ”€â”€ GRPO_COLLAPSE_ANALYSIS.md   # K=2é—®é¢˜æ·±åº¦åˆ†æ
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ready_to_train/
â”‚       â”œâ”€â”€ train_10k_final.jsonl   # è®­ç»ƒé›† (10Kæ ·æœ¬)
â”‚       â””â”€â”€ test_500_preprocessed.jsonl  # æµ‹è¯•é›†
â”‚
â””â”€â”€ logs/                       # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ training_p30.log        # æœ€æ–°å®éªŒæ—¥å¿—
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® |
|------|---------|----------|
| GPU | V100 16GB | A100 40GB |
| Python | 3.10+ | 3.10.12 |
| CUDA | 12.0+ | 12.6 |

### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/beita6969/colab-grpo.git
cd colab-grpo

# å¦‚æœæœ‰ LFS å¤§æ–‡ä»¶
git lfs pull
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. é…ç½®ç¯å¢ƒ

```bash
# é…ç½® API Key
export OPENAI_API_KEY="your-openai-api-key"

# æˆ–ä½¿ç”¨é…ç½®è„šæœ¬
source setup_env.sh
```

### 4. å¯åŠ¨è®­ç»ƒ

```bash
# æ–¹å¼1: ä½¿ç”¨å¯åŠ¨è„šæœ¬
./run_train.sh

# æ–¹å¼2: ç›´æ¥è¿è¡Œ
python train.py --config config/training.yaml
```

---

## ğŸ–¥ï¸ Google Colab ä¸€é”®å¯åŠ¨

```python
#@title AFlow-GRPO ä¸€é”®å¯åŠ¨
OPENAI_API_KEY = "sk-your-api-key"  #@param {type:"string"}

import os

# æ£€æŸ¥ GPU
!nvidia-smi --query-gpu=name,memory.total --format=csv

# å…‹éš†ä»“åº“
!git clone https://github.com/beita6969/colab-grpo.git 2>/dev/null || (cd colab-grpo && git pull)
%cd colab-grpo
!git lfs pull

# å®‰è£…ä¾èµ–
!pip install -q -r requirements.txt

# é…ç½®ç¯å¢ƒ
os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY
os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia:/usr/local/cuda/lib64'

# å¯åŠ¨è®­ç»ƒ
!python3 train.py --config config/training.yaml
```

---

## ğŸ”§ DSL è¯­æ³•

æ¨¡å‹ç”Ÿæˆçš„å·¥ä½œæµä½¿ç”¨ DSL (Domain Specific Language) è¡¨ç¤ºï¼š

| è¯­æ³• | å«ä¹‰ | ç¤ºä¾‹ |
|------|------|------|
| `->` | é¡ºåºæ‰§è¡Œ | `Custom -> Review -> Revise` |
| `[...]` | å¹¶è¡Œæ‰§è¡Œ | `[Custom, Custom, Custom] -> ScEnsemble` |
| `?` | æ¡ä»¶åˆ†æ”¯ | `Review ? Revise : done` |
| `* n` | å¾ªç¯æ‰§è¡Œ | `(Review -> Revise) * 3` |

### ç¤ºä¾‹å·¥ä½œæµ

```python
# æ•°å­¦é—®é¢˜ - ç¼–ç¨‹éªŒè¯
"Custom -> Programmer -> Review ? Revise : done"

# ä»£ç ç”Ÿæˆ - æµ‹è¯•é©±åŠ¨
"CustomCodeGenerate -> Test -> Format"

# å¤æ‚é—®é¢˜ - å¤šè·¯æŠ•ç¥¨
"[Custom, Custom, Custom] -> ScEnsemble -> Review"

# è¿­ä»£ä¼˜åŒ–
"AnswerGenerate -> (Review -> Revise) * 2 -> Format"
```

---

## ğŸ› ï¸ å¯ç”¨ Operators

| Operator | åŠŸèƒ½ | è¾“å…¥ â†’ è¾“å‡º |
|----------|------|-------------|
| **Custom** | é€šç”¨ç”Ÿæˆ | `(input, instruction)` â†’ `response` |
| **AnswerGenerate** | æ€ç»´é“¾æ¨ç† | `(input)` â†’ `thought, answer` |
| **Programmer** | ä»£ç æ‰§è¡Œ | `(problem, analysis)` â†’ `code, output` |
| **CustomCodeGenerate** | ä»£ç ç”Ÿæˆ | `(problem, entry_point, instruction)` â†’ `code` |
| **Test** | æµ‹è¯•éªŒè¯ | `(problem, solution, entry_point)` â†’ `result, solution` |
| **Review** | è§£ç­”å®¡æŸ¥ | `(problem, solution)` â†’ `review_result, feedback` |
| **Revise** | è§£ç­”ä¿®æ”¹ | `(problem, solution, feedback)` â†’ `solution` |
| **Format** | æ ¼å¼åŒ–è¾“å‡º | `(problem, solution)` â†’ `solution` |
| **ScEnsemble** | è‡ªæ´½é›†æˆ | `(solutions, problem)` â†’ `response` |
| **MdEnsemble** | å¤šæ•°æŠ•ç¥¨ | `(solutions, problem)` â†’ `solution` |

---

## âš™ï¸ é…ç½®è¯¦è§£

### ä¸»è¦å‚æ•° (`config/training.yaml`)

```yaml
# å®éªŒé…ç½®
exp_name: "aflow_grpo_k2_b3_p30"

# GRPO ç®—æ³•é…ç½®
num_return_sequences_in_group: 2   # Kå€¼: æ¯ä¸ªé—®é¢˜ç”ŸæˆKä¸ªå·¥ä½œæµ
rollout_batch_size: 3              # Bå€¼: æ¯æ‰¹å¤„ç†Bä¸ªé—®é¢˜
learning_rate: 2.0e-6              # å­¦ä¹ ç‡ (P30é™ä½10å€)
kl_loss_coef: 0.005                # KL æ•£åº¦æƒ©ç½šç³»æ•°
clip_range: 0.20                   # PPO è£å‰ªèŒƒå›´
gradient_accumulation_steps: 8     # æ¢¯åº¦ç´¯ç§¯

# LoRA é…ç½®
lora_rank: 64
lora_alpha: 64
lora_target_modules: "q_proj,k_proj,v_proj,o_proj"

# æ¸©åº¦è°ƒåº¦
temperature_schedule:
  enabled: true
  initial: 0.3
  final: 0.15
  warmup_steps: 100
```

### æ˜¾å­˜é…ç½®å»ºè®®

| GPU | æ˜¾å­˜ | K | B | grad_accum |
|-----|------|---|---|------------|
| T4 | 16GB | 2 | 2 | 8 |
| V100 | 16GB | 2 | 3 | 6 |
| A100 | 40GB | 4 | 4 | 4 |

---

## âš ï¸ å·²çŸ¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### K=2 å¯¼è‡´è®­ç»ƒå´©æºƒ

**é—®é¢˜**: å½“ `num_return_sequences_in_group=2` æ—¶ï¼Œ97.4% çš„æ¢¯åº¦æ›´æ–°åæ¨¡å‹è¾“å‡ºå´©æºƒã€‚

**åŸå› **: K=2 æ—¶ç»„å†…å½’ä¸€åŒ–å¯¼è‡´ advantage æ’ä¸º Â±1.0ï¼Œæç«¯å€¼å¯¼è‡´æ¨¡å‹ä¸ç¨³å®šã€‚

**è§£å†³æ–¹æ¡ˆ** (è¯¦è§ `docs/GRPO_COLLAPSE_ANALYSIS.md`):

```yaml
# æ–¹æ¡ˆ1: å¢åŠ  K å€¼ (æ¨è)
num_return_sequences_in_group: 8  # ä»2æ”¹ä¸º8

# æ–¹æ¡ˆ2: ä¿®æ”¹ advantage è®¡ç®—
# ç§»é™¤ std å½’ä¸€åŒ–ï¼Œåªç”¨ mean å½’ä¸€åŒ–
```

---

## ğŸ“Š å¥–åŠ±ç³»ç»Ÿ

**5çº§å¥–åŠ±**ï¼š`[0, 0.2, 0.4, 0.7, 1.0]`

```yaml
reward_weights:
  correctness: 0.65    # ç­”æ¡ˆæ­£ç¡®æ€§
  efficiency: 0.15     # æ‰§è¡Œæ•ˆç‡
  simplicity: 0.10     # å·¥ä½œæµç®€æ´åº¦
  format: 0.05         # è¾“å‡ºæ ¼å¼
  repetition: 0.05     # é‡å¤æƒ©ç½š
```

---

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

```bash
# å®æ—¶æ—¥å¿—
tail -f logs/training_p30.log

# æŸ¥çœ‹å…³é”®æŒ‡æ ‡
grep -E "Step|reward|accuracy" logs/training_p30.log | tail -50

# ä½¿ç”¨ç›‘æ§è„šæœ¬
python scripts/monitor_training.py
```

---

## ğŸ“‚ æ•°æ®é›†æ ¼å¼

```json
{
  "question": "é—®é¢˜æ–‡æœ¬",
  "answer": "æ ‡å‡†ç­”æ¡ˆ",
  "domain": "math|code|qa",
  "entry_point": "å‡½æ•°å (ä»…code)"
}
```

**æ•°æ®åˆ†å¸ƒ**ï¼šMath 33.3% / Code 33.3% / QA 33.4%

---

## ğŸ” å¸¸è§é—®é¢˜

### Q: DSL è§£æå¤±è´¥ï¼Ÿ

ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†å¸¸è§é—®é¢˜ï¼š
- `X ? Y : done` â†’ è‡ªåŠ¨è½¬æ¢ä¸º `X -> Y`
- `-> done` åç¼€ â†’ è‡ªåŠ¨ç§»é™¤

### Q: OOM (æ˜¾å­˜ä¸è¶³)ï¼Ÿ

```yaml
gradient_accumulation_steps: 8     # å¢åŠ ç´¯ç§¯
gradient_checkpointing: true       # å¯ç”¨æ£€æŸ¥ç‚¹
rollout_batch_size: 2              # å‡å°‘æ‰¹æ¬¡
```

### Q: OpenAI API è¶…æ—¶ï¼Ÿ

è°ƒæ•´ `execution_timeout: 600` æˆ–å‡å°‘ `num_return_sequences_in_group`

---

## ğŸ™ è‡´è°¢

- [AFlow](https://github.com/geekan/MetaGPT) - å·¥ä½œæµæ¡†æ¶
- [GRPO](https://arxiv.org/abs/2402.03300) - è®­ç»ƒç®—æ³•
- [Qwen2.5](https://github.com/QwenLM/Qwen2.5) - åŸºç¡€æ¨¡å‹
- [PEFT](https://github.com/huggingface/peft) - LoRA å®ç°

---

## ğŸ“„ License

MIT License

---

**æ ¸å¿ƒåˆ›æ–°**ï¼šè®©æ¨¡å‹å­¦ä¹  "å¦‚ä½•ç»„åˆå·¥å…·"ï¼Œè€Œä¸æ˜¯ "é€‰æ‹©å“ªä¸ªé¢„è®¾æ–¹æ¡ˆ"

---

*æœ€åæ›´æ–°: 2025-12-05*
